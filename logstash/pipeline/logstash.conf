input {
  beats {
    port => 5044
  }

  tcp {
    port => 50000
    codec => json
  }
}

filter {
  # 
 grok {
    match => {
      "message" => '\[%{TIMESTAMP_ISO8601:log_timestamp}\] %{DATA:log_level}: %{GREEDYDATA:log_data}'
    }
  }

  if [log_data] {
    # Remove leading and trailing curly braces
    mutate {
      gsub => ["log_data", "^\\{", "", "log_data", "\\}$", ""]
    }

    mutate {
      add_field => {
        "log_json" => "%{[log_data]}"
      }
    }

    ruby {
      code => "
        require 'json'
        log_json = event.get('log_json')
        begin
          parsed_json = JSON.parse(log_json)
          parsed_json.each { |key, value|
            event.set(key, value)
          }
           # Keep the payload field as text
          if parsed_json['payload']
            event.set('payload', parsed_json['payload'].to_json)
          end
        rescue JSON::ParserError => e
          # Handle parsing error if needed
          event.tag('_jsonparsefailure')
          event.set('json_parse_error', e.to_s)
        end
      "
    }

    date {
      match => ["log_timestamp", "ISO8601"]
      target => "@timestamp"
    }

    if [log_timestamp] {
      mutate {
        remove_field => ["log_timestamp"]
      }
    } else {
      mutate {
        add_field => { "date_parse_error" => "Timestamp not found" }
      }
    }
    if [AppName] {
      mutate {
        lowercase => ["AppName"]
        add_field => { "index_name" => "%{AppName}" }
      }
    }
    mutate {
      remove_field => ["log_data", "log_json"]
    }
  }
}

output {
  stdout { codec => rubydebug }
  if [index_name] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      user => "logstash_internal"
      password => "${LOGSTASH_INTERNAL_PASSWORD}"
      index => "%{index_name}-%{+YYYY.MM.dd}"
    }
  } else {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      user => "logstash_internal"
      password => "${LOGSTASH_INTERNAL_PASSWORD}"
    }
  }
}